## 分类任务

我们来接着做一个图片手写数字分类的项目，使用**MNIST**数据集。

#### 1	获取数据

​	`sklearn`提供了很多有用的函数来帮助我们获取一些热门的数据集，例如我们将要使用的MNIST，我们将使用如下的代码来获取这个数据集。注意，这里我们首先对数据进行了排序。

```python
from sklearn.datasets import fetch_openml
import numpy as np

def sort_by_target(mnist):
	reorder_train = np.array(sorted([(target, i) for i, target in enumerate(mnist.target[:60000])]))[:, 1]
	reorder_test = np.array(sorted([(target, i) for i, target in enumerate(mnist.target[60000:])]))[:, 1]
	mnist.data[:60000] = mnist.data[reorder_train]
	mnist.target[:60000] = mnist.target[reorder_train]
	mnist.data[60000:] = mnist.data[reorder_test + 60000]
	mnist.target[60000:] = mnist.target[reorder_test + 60000]
    
mnist = fetch_openml('mnist_784', version=1, cache=True)
mnist.target = mnist.target.astype(np.int8)  # 这是因为fetch_openml返回的是字符串
sort_by_target(mnist)
```

​	使用`fetch_openml`获取的数据集大多有如下特征：

-   一个`data`键值，储存对象为一个二维数组，每一行都是一个实例，每一列都是一个特征
-   一个`target`键值，储存`labels`

​	我们最好将数据重新洗牌，这样就能保证我们的交叉验证集能包含所有的数字（而不是一个数字的各种形态）：

```python
np.random.seed(42)
shuffle_index = np.random.permutation(60000) # 产生一个从0到60000的随机序列
X_train, y_train = X_train[shuffle_index], y_train[shuffle_index]
```

#### 2	训练一个二元分类器

​	首先，我们来训练一个能判断一个数字是不是$5$的分类器。我们使用随机梯度下降分类器来完成这个操作。使用`sklearn`中的`SGDClassifier`即可完成这个操作。该分类器在处理大型数据的时候非常迅速，这部分由于它能挨个处理训练集中的实例，每次处理一个（这个特征也让它非常适合线上学习）。

```python
y_train_5 = (y_train == 5)
y_test_5 = (y_test == 5)
sgd_clf = SGDClassifier(random_state=42)
sgd_clf.fit(X_train, y_train)
```

#### 3	评估这个二元分类器的效果

​	相比于如何分类，如何评估分类器的效果才是重中之重。

##### 3.1	交叉评估

​	就像我们之前那么干的，使用交叉评估是一个比较好的方法来评估我们的分类器的效果。除了使用之前提到的内置的`cross_val_score()`函数，我们也可以自己定义一个功能相同的函数，来获得更多的自由和操作空间：

```python
from sklearn.model_selection import StratifiedKFold
from sklearn.base import clone
def cross_val_evaluate(train_data, train_labels, clf):
	skfolds = StratifiedKFold(n_splits=3)
	for train_index, test_index in skfolds.split(train_data, train_labels):
		clone_clf = clone(clf)
		train_data_folds = train_data[train_index]
		train_labels_folds = train_labels[train_index]
		test_data_folds = train_data[test_index]
		test_labels_folds = train_labels[test_index]
		clone_clf.fit(train_data_folds, train_labels_folds)
		prediction = clone_clf.predict(test_data_folds)
		n_correct = sum(prediction == test_labels_folds)
		print(n_correct / len(prediction))
```

>   `StratifiedKFold`类实现了分层采样（详见第二章的解释），生成的折（fold）包含了各类相应比例的样例。**在每一次迭代**，上述代码生成分类器的一个克隆版本，在训练折（training folds）的克隆版本上进行训练，在测试折（test folds）上进行预测。然后它计算出被正确预测的数目和输出正确预测的比例。最后的结果是每一次迭代得到的正确率的平均值

​	让我们使用`cross_val_score()`函数来评估`SGDClassifier`模型，同时使用 K 折交叉验证，此处让`k=3`。记住：K 折交叉验证意味着把训练集分成 K 折（此处 3 折），然后使用一个模型对其中一折进行预测并记录正确率，对其他折进行训练。

```python
print(cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring='accuracy'))
```

​	我们得到的结果是$[ 0.9502 ,\, 0.96565,\ 0.96495]$，这似乎是一个令人惊叹的准确率。但是考虑到我们仅仅只是判断一个数是不是5，哪怕我们简单的认为所有的数都不是5，成功率也将高达$0.9$，假设所有数字所占的比例几乎相同。针对本数据集，下面的代码给出了全部认为不是5的分类器的验证结果。

```python
from sklearn.base import BaseEstimator
class Never5Classifier(BaseEstimator):
    def fit(self, X, y=None):
        pass
    def predict(self, X):
        return np.zeros((len(X), 1), dtype=bool)
never_5_clf = Never5Classifier()
cross_val_score(never_5_clf, X_train, y_train_5, cv=3, scoring="accuracy")
# array([ 0.909 , 0.90715, 0.9128 ])
```

​	上面的实验表明，在分类任务中由于**基准概率**的存在以及其**随着数据特征变动**而变动，使用判断正确率来衡量一个模型的准确度并不是一个好办法。特别是当我们的数据集中某一类的数据异常的多（例如上面的非5的数据特别的多）的时候。

##### 3.2	混淆矩阵

​	对于分类器来说，一个更好的办法是使用混淆矩阵。其基本原理在于观测一个对象A有多少次被分类为B。举例来说，当我们想要知道一个图片数字5被错认为数字3的次数，我们就可以查询混淆矩阵的第5行第3列。

​	要计算混淆矩阵，我们需要使用数据来得出预测结果，并将其与标签值对比。注意，**不要使用我们的测试集**，而是使用训练集中的一部分作为数据。直到我们最终对模型很有信心了，才应该使用未曾被触碰过的训练集做最终验证。我们使用`cross_val_predict()`来完成这个操作：

```python
from sklearn.model_selection import cross_val_predict
y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3)
```

​	就像 `cross_val_score()`，`cross_val_predict()`也使用 K 折交叉验证。它不返回一个评估分数，而返回基于每一个测试折（Fold）做出的一个预测值。这意味着，对于每一个训练集的样例，你得到一个干净的预测（“干净”是说一个模型在训练过程当中没有用到测试集的数据）。

```python
from sklearn.metrics import confusion_matrix
confusion_matrix(y_train_5, y_train_pred)
#	array([[53272, 1307], 
#		 [ 1077, 4344]])
```

​	混淆矩阵中的每一行表示一个实际的类, 而每一列表示一个预测的类。该矩阵的第一行认为“非 5”（反例）中的 53272 张被正确归类为 “非 5”（真反例，*True negatives, TN*）, 而其余 1307 被错误归类为"是 5" （假正例，*False positives, FP*）。第二行认为“是 5” （正例）中的 1077 被错误地归类为“非 5”（假反例，*False negatives, FN*），其余 4344 正确分类为 “是 5”类（真正例，*True positives, TP*）。一个完美的分类器将只有真反例和真正例，所以混淆矩阵的非零值仅在其主对角线（左上至右下）。

##### 3.3	精度与回收率

​	从混淆矩阵中我们可以看出模型对某个特征的判断精确度，例如我们将
$$
\textrm{precision}= \frac{TP}{TP+FP}
$$
称为精度，也就是当分类器认为这张图片是5时，它预测正确的概率。其中$TP$表示*True Positive*，为预测正确的5的个数。$FP$为False Positive，为将不是5的图片错认为5的个数。同时我们将
$$
\textrm{recall} = \frac{TP}{TP + FN}
$$
称为回收率，也就是当一张图片真的是5的时候，分类器将其正确分类为5的概率。其中$FN$表示False Positive，表示将一个原本就是5的图片错误标记为非5图片的次数。

​	我们可以使用`sklearn`中的`precision_score`，`recall_score`来分别计算这两个概率：

```python
from sklearn.metrics import precision_score, recall_score
precision_score(y_train_5, y_pred)		# == 4344 / (4344 + 1307)
recall_score(y_train_5, y_train_pred) 	# == 4344 / (4344 + 1077)
```

​	我们可以使用如下的方法将上面的两个预测概率转化为一个综合的概率，其被称为*F1*值。
$$
F_1=\frac{2}{\frac{2}{\textrm{precision}}+\frac{1}{\textrm{recall}}}
$$
我们也可以直接使用`f1_score`来计算这个：

```python
from sklearn.metrics import f1_score
f1_score(y_train_5, y_pred)
```

​	注意，精度和回收率是很难以同时很高的，我们要在这二者之间进行取舍，考虑我们的问题究竟是需要高精度的预测，还是高回收率的预测。例如，过滤儿童不良影片的分类器应该是高精度的，哪怕它的回收率很低。我们宁可它误杀很多好的影片，也不希望放过一个不良影片。

​	想要调整我们的模型的精度、回收率，首先要知道我们的模型是怎么完成分类工作的。随机梯度下降分类器根据他的决策函数给每一个实例一个估值，如果这个估值大于某个阈值，那么分类器就会将这个实例分类到Positive Class；反之，则会将其分类到Negative Class。我们只要调整这个阈值的大小就能调整精度和回收率之间的关系。将阈值降低可以提高回收率，但会降低精度。将阈值提高可以提高精度，但是降低回收率

​	但是`sklearn`并没有提供给我们直接操作这个阈值的方法，但是我们还是有获取上述描述中的估值的办法，接着我们可以手动使用这些估值来进行分类。首先我们使用`decision_function`**求出对应实例的估值**，然后手动设置一个阈值`threshold`，估值大于这些阈值的数将被分类为Positive:

```python
some_ditgit = X[36000]
y_scores = sgd_clf.decision_function([some_digit])
threshold = 10000	# 可以手动调整这个值了
y_some_digit_pred = (y_scores > threshold)
```

​	如果我们想要找到一个较为合适的阈值，我们可能希望对它**进行多次实验**。除了手动调整阈值之外，我们还可以使用`cross_val_predict`函数来完成，只是这时候记得设置参数`method="decision_function"`来使其不直接返回预测，而是返回估值。

```python
y_scores = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3,
                             method="decision_function")
```

​	有了这些估值，接着我们可以使用`precision_recall_curve`来刻画所有可能的阈值对应的结果：

```python
from sklearn.metrics import precision_recall_curve 
precisions, recalls, thresholds = precision_recall_curve(y_train_5, y_scores)
#	出于某种不知道的原因，这里得到的threshold居然比另外两个数据少了最后一位
plt.plot(thresholds, precisions[:-1], "b--", label="Precision", linewidth=2)
plt.plot(thresholds, recalls[:-1], "g-", label="Recall", linewidth=2)
```

或者我们可以画一个$\textrm{precision-recall}$关系图：

```python
plt.plot(precisions, recalls)
```

#### 4	训练一个多元分类器

​	之前我们的模型只能对一个实例进行二元分类，而现在我们需要训练一个能分类多个类别的实例。具体来说，我们需要一个能将图片分类为$1,2,3,\ldots，9$的分类器。

​	某些算法天生就支持多元分类，例如随机森林分类器或者朴素贝叶斯分类器，但是有些算法只严格支持二分类，例如支持向量机和线性分类器。当然，我们也有一些办法让后者来支持多元分类。比如，我们可以创建10个二分类器来分别判断是不是$1,2,\ldots,9$，这个方法称为*One-versus-all*（*OVA*）方法。或者，我们可以给每一对数据都创建一个二分类器，分别区分$(0,1),(0,2)\ldots(8,9)$。这种方法称为*One-versus-one*(*OvO*)方法在这里我们就需要创建45个分类器，虽然看起来有点多，但是这个方法的好处在于我们只需要使用一部分数据来训练这个模型，这就使得某些对大规模数据支持性不佳的算法（例如支持向量机分类器）特别适用这种方法。

​	`sklearn`如果发现我们在使用二分类器来进行多元分类，它会自动运行一个OVA方法来将其转换为多元分类器（如果使用的是支持向量机模型，则会自动使用OvO方法）。例如：

```python
sgd_clf.fit(X_train, y_train) # y_train, not y_train_5
```

上面的代码在训练集上训练了一个`SGDClassifier`。这个分类器处理原始的目标class，从 0 到 9（`y_train`），而不是仅仅探测是否为 5 （`y_train_5`）。然后它做出一个判断（在这个案例下只有一个正确的数字）。在幕后，Scikit-Learn 实际上训练了 10 个二分类器，每个分类器都产到一张图片的决策数值，选择数值最高的那个类。

​	为了证明这是真实的，你可以调用`decision_function()`方法。不是返回每个样例的一个数值，而是返回 10 个数值，一个数值对应于一个类。

```python
>>> some_digit_scores = sgd_clf.decision_function([some_digit])
>>> some_digit_scores
array([[-311402.62954431, -363517.28355739, -446449.5306454 ,
        -183226.61023518, -414337.15339485, 161855.74572176,
        -452576.39616343, -471957.14962573, -518542.33997148,
        -536774.63961222]])
>>> np.argmax(some_digit_scores)
5
```

>   区分`argmax`与`max`：
>
>   -   `argmax`找的是第几个参数最大，或者说最大值的位置在哪里。计数从0开始
>   -   `max`找的是最大的值是多少

#### 5	误差分析

​	假设我们已经决定使用随机森林模型了，接下来就是如何优化数据和模型，提升准确度的工作了。想要知道我们的模型在哪些方面还有问题，我们首先要观察我们的数据，或者说，混淆矩阵。使用`cross_val_predict`和`confusion_martix`函数我们可以得到混淆矩阵

```python
y_train_pred = cross_val_predict(sgd_clf, X_train_scaled, y_train, cv=3)
conf_mx = confusion_matrix(y_train, y_train_pred)
```

​	这个矩阵是一个巨大的、数据分布杂乱无章的矩阵。我们可以将其图形化为一个灰度矩阵：

```python
plt.matshow(conf_mx, cmap=plt.cm.gray)
```

不过这样得到的图形仍然不够直观，我们首先可以将其值全部除以混淆矩阵每一行的对应的和，求出其准确率$\textrm{precision}$，再把判断准确的那些数据全部置为0，就可以只关注错误率了。

```python
row_sums = conf_mx.sum(axis=1, keepdims=True)	# 以列，即相应类别图片的总数。保留维度
norm_conf_mx = conf_mx / row_sums
np.fill_diagonal(norm_conf_mx, 0)
plt.matshow(norm_conf_mx, cmap=plt.cm.gray)
```

<img src="https://pimags.oss-cn-beijing.aliyuncs.com/image-20200423230413960.png" alt="image-20200423230413960" style="zoom: 40%;" />

​	现在你可以清楚看出分类器制造出来的各类误差。记住：行代表实际类别，列代表预测的类别。第 8、9 列相当亮，这告诉你许多图片被误分成数字 8 或者数字 9。相似的，第 8、9 行也相当亮，告诉你数字 8、数字 9 经常被误以为是其他数字。相反，一些行相当黑，比如第一行：这意味着大部分的数字 1 被正确分类（一些被误分类为数字 8 ）。留意到误差图不是严格对称的。举例子，比起将数字 8 误分类为数字 5 的数量，有更多的数字 5 被误分类为数字 8。

​	分析混淆矩阵通常可以给你提供深刻的见解去改善你的分类器。回顾这幅图，看样子你应该努力改善分类器在数字 8 和数字 9 上的表现，和纠正 3/5 的混淆。举例子，你可以尝试去收集更多的数据，或者你可以构造新的、有助于分类器的特征。举例子，写一个算法去数闭合的环（比如，数字 8 有两个环，数字 6 有一个， 5 没有）。又或者你可以预处理图片（比如，使用 Scikit-Learn，Pillow， OpenCV）去构造一个模式，比如闭合的环。

#### 6	多标签分类器

​	到目前为止，所有的样例都总是被分配到仅一个类。有些情况下，你也许想让你的分类器给一个样例输出多个类别。比如说，思考一个人脸识别器。如果对于同一张图片，它识别出几个人，它应该做什么？当然它应该给每一个它识别出的人贴上一个标签。比方说，这个分类器被训练成识别三个人脸，Alice，Bob，Charlie；然后当它被输入一张含有 Alice 和 Bob 的图片，它应该输出`[1, 0, 1]`（意思是：Alice 是，Bob 不是，Charlie 是）。这种输出多个二值标签的分类系统被叫做多标签分类系统。

​	我们使用K临近分类器来完成这个操作。注意不是所有的分类器都支持多标签分类。

```python
from sklearn.neighbors import KNeighborsClassifier
y_train_large = (y_train >= 7)
y_train_odd = (y_train % 2 == 1)
y_multilabel = np.c_[y_train_large, y_train_odd]
knn_clf = KNeighborsClassifier() 
knn_clf.fit(X_train, y_multilabel)
```

​	这段代码创造了一个`y_multilabel`数组，里面包含两个目标标签。第一个标签指出这个数字是否为大数字（7，8 或者 9），第二个标签指出这个数字是否是奇数。接下来几行代码会创建一个`KNeighborsClassifier`样例（它支持多标签分类，但不是所有分类器都可以），然后我们使用多目标数组来训练它。现在你可以生成一 个预测，然后它输出两个标签：

```python
>>> knn_clf.predict([some_digit])
array([[False, True]], dtype=bool)
```

​	有许多方法去评估一个多标签分类器，和选择正确的量度标准，这取决于你的项目。举个例子，一个方法是对每个个体标签去量度 F1 值（或者前面讨论过的其他任意的二分类器的量度标准），然后计算平均值。下面的代码计算全部标签的平均 F1 值：

```python
>>> y_train_knn_pred = cross_val_predict(knn_clf, X_train, y_train, cv=3)
>>> f1_score(y_train, y_train_knn_pred, average="macro")
0.96845540180280221
```

​	这里假设所有标签有着同等的重要性，但可能不是这样。特别是，如果你的 Alice 的照片比 Bob 或者 Charlie 更多的时候，也许你想让分类器在 Alice 的照片上具有更大的权重。一个简单的选项是：给每一个标签的权重等于它的支持度（比如，那个标签的样例的数目）。为了做到这点，简单地在上面代码中设置`average="weighted"`。

#### 7	多输出分类

​	我们即将讨论的最后一种分类任务被叫做“**多输出-多类分类**”（或者简称为多输出分类）。它是多标签分类的简单泛化，在这里每一个标签可以是多类别的（比如说，它可以有多于两个可能值）。

​	为了说明这点，我们建立一个系统，它可以去除图片当中的噪音。它将一张混有噪音的图片作为输入，期待它输出一张干净的数字图片，用一个像素强度的数组表示，就像 MNIST 图片那样。注意到这个分类器的输出是多标签的（一个像素一个标签）和每个标签可以有多个值（像素强度取值范围从 0 到 255）。所以它是一个多输出分类系统的例子。

>   分类与回归之间的界限是模糊的，比如这个例子。按理说，预测一个像素的强度更类似于一个回归任务，而不是一个分类任务。而且，多输出系统不限于分类任务。你甚至可以让你一个系统给每一个样例都输出多个标签，包括类标签和值标签。

​	让我们从 MNIST 的图片创建训练集和测试集开始，然后给图片的像素强度添加噪声，这里是用 NumPy 的`randint()`函数。目标图像是原始图像。

```python
noise = rnd.randint(0, 100, (len(X_train), 784))
noise = rnd.randint(0, 100, (len(X_test), 784))
X_train_mod = X_train + noise
X_test_mod = X_test + noise
y_train_mod = X_train
y_test_mod = X_test

knn_clf.fit(X_train_mod, y_train_mod)
clean_digit = knn_clf.predict([X_test_mod[some_index]])
plot_digit(clean_digit)
```

